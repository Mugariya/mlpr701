{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATTACK_EPS = 0.5\n",
    "ATTACK_STEPSIZE = 0.1\n",
    "ATTACK_STEPS = 10\n",
    "NUM_WORKERS = 8\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as ch\n",
    "from robustness.datasets import FashionMnist\n",
    "ds = FashionMnist('/tmp/FashionMNIST')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint '/home/ashraf.haddad/mlpr/Fashion_Store_ADV/checkpoint.pt.best'\n",
      "=> loaded checkpoint '/home/ashraf.haddad/mlpr/Fashion_Store_ADV/checkpoint.pt.best' (epoch 36)\n"
     ]
    }
   ],
   "source": [
    "from robustness.model_utils import make_and_restore_model\n",
    "model, _ = make_and_restore_model(arch='resnet18', dataset=ds,\n",
    "              resume_path= '/home/ashraf.haddad/mlpr/Fashion_Store_ADV/checkpoint.pt.best') #'/tmp/35daedae-1b39-4941-ad08-8bd6459c1bd8/checkpoint.pt.best')\n",
    "model.eval()\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing dataset fashionmnist..\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /tmp/FashionMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8eec866a73d4626a5869b3552c680ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26421880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/FashionMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz to /tmp/FashionMNIST/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /tmp/FashionMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bb4597e88f7467490aab761b64cd22c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/FashionMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /tmp/FashionMNIST/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /tmp/FashionMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc43fec50c944028ad05db10b2976dad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4422102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/FashionMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /tmp/FashionMNIST/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /tmp/FashionMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16c0c11a4a6e4415b054d99ba54cf6ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/FashionMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/FashionMNIST/FashionMNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashraf.haddad/.conda/envs/rob/lib/python3.9/site-packages/torchvision/datasets/mnist.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1614378073850/work/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n",
      "/home/ashraf.haddad/.conda/envs/rob/lib/python3.9/site-packages/torchvision/datasets/mnist.py:58: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 <class 'torch.Tensor'>\n",
      "cuda:0 <class 'torch.Tensor'>\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# device will be 'cuda' if a GPU is available\n",
    "device = ch.device('cuda' if ch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#only load the validation set\n",
    "_, test_loader = ds.make_loaders(workers=NUM_WORKERS, batch_size=BATCH_SIZE)\n",
    "_, (im, label) = next(enumerate(test_loader))  \n",
    "im,label = im.to(device),label.to(device)\n",
    "\n",
    "\n",
    "print(im.device, type(im))\n",
    "print(label.device,type(label))\n",
    "print(next(model.parameters()).device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating untargeted adversarial examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kwargs = {\n",
    "    'constraint':'2', # use L2-PGD\n",
    "    'eps': ATTACK_EPS, # L2 radius around original image\n",
    "    'step_size': ATTACK_STEPSIZE,\n",
    "    'iterations': ATTACK_STEPS,\n",
    "    'do_tqdm': True,\n",
    "}\n",
    "label.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current loss: 0.33939820528030396: 100%|████████| 10/10 [00:02<00:00,  4.11it/s]\n"
     ]
    }
   ],
   "source": [
    "#the model can generate adv by applying max l-infinity loss\n",
    "_, im_adv = model(im, label, make_adv=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from robustness.tools.vis_tools import show_image_row\n",
    "from robustness.tools.label_maps import CLASS_DICT\n",
    "\n",
    "# Get predicted labels for adversarial examples using \n",
    "pred, _ = model(im_adv)\n",
    "label_pred = ch.argmax(pred, dim=1)\n",
    "delta_label = ch.tensor(BATCH_SIZE*[-1]) #noise\n",
    "\n",
    "# Visualize test set images, along with corresponding adversarial examples\n",
    "show_image_row([im.cpu(), im_adv.cpu(),50*(im-im_adv).cpu()],\n",
    "         tlist=[[CLASS_DICT['FashionMnist'][int(t)] for t in l] for l in [label, label_pred,delta_label]],\n",
    "         fontsize=18,\n",
    "         filename='./adversarial_example_FASHION.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'T-Shirt'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLASS_DICT['FashionMnist'][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Targeted adversarial examples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
